# 定量的指標

> 定義したアーキテクチャ特性を定量的に測定するための指標とその計測方法などを調べる.

## アーキテクチャ特性ごとの定量的指標

---
### 機能完全性(Functional Completeness)
---
#### 網羅率 (Coverage Rate)
- 定義された要件に対して実装された機能の割合を示す指標.
- 指標例: 実装済み機能数 ÷ 定義された全機能数 × 100%
#### 要件達成度 (Requirement Fulfillment Rate)
- ユーザーの目的や期待に基づいて, システムがどれだけ多くの要求を満たしているかを評価.
- 指標例: 満たされた要件数 ÷ 全要件数 × 100%
#### 機能欠如の数 (Number of Missing Features)
- 定義された機能の中で, まだ実装されていない機能の数.

---
### 機能正確性(Functional Correctness)
---
#### テストケースの合格率 (Test Case Pass Rate)
- システムの機能が定義どおりに正確に動作しているかを, テストケースを通じて確認.
- 指標例: 成功したテストケース数 ÷ 全テストケース数 × 100%
#### バグ密度 (Bug Density)
- 実装された機能におけるエラーの割合.システムの正確さを示す指標として, リリース後のバグやエラーの数を使用.
- 指標例: 発見されたバグの数 ÷ コードの行数
#### 境界条件テスト合格率 (Boundary Condition Test Pass Rate)
- 境界条件や極端なシナリオでのテストケースの合格率を示す指標.
- 指標例: 境界テストで成功したケース数 ÷ 境界テストケース数 × 100%
#### データの正確性 (Data Accuracy)
- 入力データに対して, 出力されるデータがどれだけ正確かを測定.

---
### 機能的妥当性(Functional Appropriateness)
---
#### ユーザー満足度スコア (User Satisfaction Score)
- システムが指定されたタスクをどれだけ効果的に達成できるか, ユーザーにアンケートを通じて評価.
- 指標例: ユーザーのフィードバックによる満足度スコア（1-10のスケールなど）.
#### タスク完了時間 (Task Completion Time)
- 特定のタスクや操作がどれだけ迅速に行えるかを評価するための指標.
- 指標例: 各タスクの平均完了時間（秒/分）.
#### エラー率 (Error Rate)
- ユーザーがタスクを完了する際に発生するエラーの割合を測定.
- 指標例: ユーザーあたりのエラー発生数 ÷ 全ユーザー数
#### タスク達成率 (Task Success Rate)
- ユーザーが機能を使って指定されたタスクをどれだけ成功裏に完了できるか.
- 指標例: 成功したタスクの数 ÷ 試行回数 × 100%
#### ユーザビリティテスト合格率 (Usability Test Pass Rate)
- ユーザビリティテストで, ユーザーが指定されたタスクや目的をどれだけ容易に達成できたかの割合.
- 指標例: 合格したユーザビリティテストケース数 ÷ 総テストケース数 × 100%

---
### タイムリネス(Timeliness)
---
#### 平均応答時間 (Average Response Time)
- システムがリクエストに対して応答するまでの平均時間を計測.
- 指標例: システムに送信されたリクエストの応答時間の合計 ÷ リクエストの総数
#### 遅延時間 (Latency)
- リクエストから応答が返されるまでの最小時間.リアルタイムシステムでの評価が重要.
- 指標例: 最低応答時間, 最高応答時間, パーセンタイル応答時間（90%, 95%など）
#### スループット (Throughput)
- 一定時間内に処理できたリクエスト数を示す.
- 指標例: 処理されたリクエスト数 ÷ 秒
#### タスク完了時間 (Task Completion Time)
- タスクや処理が完了するまでに要する平均時間.
- 指標例: 各タスクの完了時間の平均（秒, 分）

---
### 効率性(Efficiency) 
---
#### CPU使用率 (CPU Utilization)
- システムのCPU資源がどれだけ使用されているかを計測.CPU使用率が高すぎる場合, 効率が悪い可能性がある.
- 指標例: 使用されているCPU時間 ÷ 総CPU時間 × 100%
#### メモリ消費量 (Memory Usage)
- システムがどれだけのメモリを消費しているか.過剰なメモリ使用はシステムパフォーマンスを低下させる可能性がある.
- 指標例: 使用メモリ量 ÷ 総メモリ量 × 100%
#### ディスクI/O使用率 (Disk I/O Utilization)
- データの読み書きにどれだけディスクリソースが消費されているかを示す.
- 指標例: ディスクアクセス量 ÷ 最大容量
#### エネルギー消費量 (Energy Consumption)
- システム運用に必要な電力消費量.特にデータセンターやモバイルデバイスにおいて重要.
- 指標例: システムの消費電力量（kWhなど）
#### リクエストあたりのコスト (Cost per Request)
- リクエストや処理にかかるコストを算出.サーバー利用やクラウドサービスでの運用コスト評価.
- 指標例: 総コスト ÷ 処理リクエスト数

---
### スケーラビリティ(Scalability) 
---
#### 同時接続数 (Concurrent Users)
- システムが同時に処理可能なユーザー数.
- 指標例: 最大同時接続ユーザー数
#### リクエスト処理能力 (Request Handling Capacity)
- システムが1秒間に処理可能なリクエストの最大数.
- 指標例: リクエスト/秒
#### 水平スケーリングの効果 (Horizontal Scalability Effectiveness)
- サーバーやノードの追加によるパフォーマンスの向上度合いを示す.
- 指標例: 追加されたサーバー/ノード数に対して, パフォーマンスの向上率（%）
#### 縦方向スケーリングの効果 (Vertical Scalability Effectiveness)
- ハードウェアの性能向上によるパフォーマンスの改善度合いを示す.
- 指標例: 増強されたリソースに対して, パフォーマンスの向上率（%）
#### 負荷分散効率 (Load Balancing Efficiency)
- システムが負荷分散によって負荷をどれだけ均等に処理しているか.
- 指標例: 各サーバーへの負荷分散割合のバランス

---
### 弾力性(Elasticity)
---
#### スケールアップ/スケールダウンの反応時間 (Scale Up/Down Response Time)
- 負荷が増加した際に, システムがリソースをスケーリングするまでに要する時間.
- 指標例: スケールアップまたはダウンの所要時間（秒, 分）
#### 自動スケーリング精度 (Auto-Scaling Accuracy)
- 負荷の変動に応じて, 適切なリソース量が自動でスケーリングされた精度を評価.
- 指標例: 実際のリソース需要とスケーリングされたリソース量の差異
#### 負荷ピーク時のスループット変動 (Throughput Variance During Peak Load)
- 負荷のピーク時におけるスループットの変動を計測.弾力性の指標となる.
- 指標例: ピーク時スループットの変動率（%）
#### 利用率の変動幅 (Utilization Variability)
- リソースの使用率が, 負荷の変動にどれだけ対応しているかを示す.
- 指標例: 最小利用率と最大利用率の差（%）

---
### 可用性(Availability)
---
#### 稼働時間 (Uptime)
- システムが指定された期間中にどれだけの時間稼働しているかを示す指標.
- 指標例: (総稼働時間 ÷ 総時間) × 100%
#### ダウンタイム (Downtime)
- システムが利用できない時間の合計.障害発生時の修復にかかる時間も含む.
- 指標例: 1年間あたりの合計ダウンタイム時間（分, 時間）
#### 可用率 (Availability Rate)
- システムが稼働可能な時間の割合.
- 指標例: (稼働時間 ÷ 予定稼働時間) × 100%
#### サービスレベル契約 (SLA) 遵守率
- 定められたSLAに対する実際の可用性の割合.
- 指標例: SLAで定義された可用率（例: 99.9%）

---
### 信頼性(Reliability)
---
#### 平均故障間隔 (MTBF: Mean Time Between Failures)
- システムがエラーや故障を起こすまでの平均時間.
- 指標例: 稼働時間 ÷ 故障回数
#### 平均故障率 (Failure Rate)
- 一定期間における故障の頻度を表す指標.
- 指標例: 故障回数 ÷ 稼働時間
#### 故障の頻度 (Failure Frequency)
- 一定期間内に発生した故障の回数.
- 指標例: 1か月あたりの故障回数

---
### 回復性(Recoverability)
---
#### 平均復旧時間 (MTTR: Mean Time to Recovery)
- システムが故障や障害から回復するまでの平均時間を示す指標.
- 指標例: 修復時間 ÷ 修復イベント数
#### 回復率 (Recovery Rate)
- システムが故障からどれだけ早く回復できるかを評価する指標.
- 指標例: 成功した回復の数 ÷ 回復試行の数
#### ダウンタイム削減率
- システムが障害から復旧する速度の改善率を評価する指標.
- 指標例: （以前のダウンタイム − 現在のダウンタイム） ÷ 以前のダウンタイム × 100%

---
### 耐障害性(Fault Tolerance)
---
#### 冗長性 (Redundancy)
- システムが一部のコンポーネントが故障しても, 冗長構成により機能を維持できる度合い.
- 指標例: 冗長化されたシステム数 ÷ 全システム数
#### フェイルオーバー時間 (Failover Time)
- 主要なコンポーネントが故障した際, システムがバックアップに切り替わるまでの時間.
- 指標例: フェイルオーバーに要する平均時間（秒, 分）
#### システム停止防止率 (System Downtime Prevention Rate)
- 部分的な障害が発生しても, システムが停止することなく稼働し続ける割合.
- 指標例: 防止された停止回数 ÷ 全停止イベント数

---
### 堅牢性(Robustness)
---
#### 異常処理率 (Error Handling Rate)
- 異常な入力や外部からの攻撃に対して, システムが正しく対処できる割合.
- 指標例: 処理されたエラーイベント数 ÷ 発生したエラーイベント数 × 100%
#### クラッシュ防止率 (Crash Prevention Rate)
- 異常条件下でシステムがクラッシュを回避できる割合.
- 指標例: 回避されたクラッシュの数 ÷ 発生した異常イベント数 × 100%
#### 入力検証エラー率 (Input Validation Error Rate)
- 不正な入力に対して, システムが適切にエラー処理を行った回数の割合.
- 指標例: 検知された不正入力の数 ÷ 全入力の数 × 100%

---
### 耐久性(Durability)
---
#### データ保持率 (Data Retention Rate)
- システムがデータを長期間にわたって保持し, 失わずに管理できる割合.
- 指標例: 保持されているデータ量 ÷ 保存されたデータ量 × 100%
#### システムの寿命 (System Lifetime)
- システムが長期間にわたり機能を維持する平均期間.
- 指標例: システムが稼働できた年数, または使用可能な時間（年, 月）
#### ハードウェアの寿命 (Hardware Lifetime)
- ハードウェアコンポーネントが故障せずに動作し続ける平均期間.
- 指標例: 平均使用年数または平均稼働時間

---
### 操作性(Operability)
---
#### クリック数 (Number of Clicks)
- 目的の操作を完了するまでに必要なクリックやアクションの数を測定.
- 指標例: タスク完了に必要なクリック数（平均クリック数）
#### 操作時間 (Task Completion Time)
- ユーザーが特定のタスクを完了するまでにかかる時間.
- 指標例: 各タスクの完了時間（秒, 分）
#### ナビゲーションエラー率 (Navigation Error Rate)
- ユーザーが操作中に意図しないページや機能に移動する割合.
- 指標例: 誤操作の回数 ÷ 全操作回数 × 100%
#### ユーザー満足度スコア (User Satisfaction Score)
- 操作性に対するユーザーの満足度をアンケート等で収集しスコア化.
- 指標例: 1〜10のスケールで評価されるユーザーの満足度平均スコア.

---
### ユーザエラー防止性(User Error Protection)
---
#### エラー防止率 (Error Prevention Rate)
- システムがエラーを防止する回数や割合を示す.
- 指標例: システムが防いだエラー回数 ÷ 全エラー回数 × 100%
#### フィードバック提供率 (Feedback Response Rate)
- ユーザーが誤入力や不正操作を行った際に, 適切なフィードバックが提供された割合.
- 指標例: フィードバックが正しく表示された回数 ÷ 全誤操作数 × 100%
#### 取り消し可能操作数 (Undoable Action Rate)
- 取り消し可能な操作の割合.
- 指標例: 取り消し機能を使用できる操作数 ÷ 全操作数 × 100%

---
### アクセシビリティ(Accessibility)
---
#### アクセシビリティ準拠率 (Accessibility Compliance Rate)
- システムがWCAG（Web Content Accessibility Guidelines）やADA（Americans with Disabilities Act）などのアクセシビリティ標準に準拠している割合.
- 指標例: 準拠している基準数 ÷ 全基準数 × 100%
#### 支援技術互換性率 (Assistive Technology Compatibility Rate)
- 画面読み上げソフトやキーボードナビゲーションなど, 支援技術との互換性を測定.
- 指標例: 支援技術で正常動作する機能数 ÷ 全機能数 × 100%
#### ユーザーアクセシビリティ満足度スコア
- アクセシビリティ機能に対するユーザーの満足度.
- 指標例: ユーザーアンケートによる評価（1〜10のスケール）

---
### 学習容易性(Learnability)
---
#### 学習時間 (Learning Time)
- ユーザーがシステムの基本操作を習得するまでにかかる平均時間.
- 指標例: 基本タスクの平均習得時間（分, 時間）
#### ガイドやチュートリアルの完了率 (Tutorial Completion Rate)
- 初心者向けのガイドやチュートリアルを完了したユーザーの割合.
- 指標例: チュートリアルを完了したユーザー数 ÷ チュートリアル開始ユーザー数 × 100%
#### 学習エラー率 (Learning Error Rate)
- 学習プロセスで発生するエラーの頻度.
- 指標例: 学習過程でのエラー回数 ÷ 総学習イベント数 × 100%

---
### ローカライゼーション(Localization)
---
#### 多言語対応率 (Multilingual Support Rate)
- システムが対応している言語の数と, ターゲットユーザーの使用言語に対するカバー率.
- 指標例: サポート言語数 ÷ ターゲット言語数 × 100%
#### 文化的適応度 (Cultural Adaptation Score)
- 翻訳の質や, 文化的な適合性を測定するスコア.アンケートなどを使って収集.
- 指標例: ユーザーからの文化適応に関するフィードバックスコア（1〜10のスケール）

---
### インストール容易性(Installability)
---
#### インストール成功率 (Installation Success Rate)
- ユーザーが問題なくシステムをインストールできる割合.
- 指標例: 成功したインストール数 ÷ インストール試行数 × 100%
#### インストール時間 (Installation Time)
- システムをインストールするのにかかる平均時間.
- 指標例: インストール開始から完了までの平均時間（分, 秒）
#### インストールエラー率 (Installation Error Rate)
- インストール中に発生するエラーの割合.
- 指標例: エラーが発生したインストール数 ÷ 全インストール数 × 100%

---
### アップグレード容易性(Upgradeability)
---
#### アップグレード成功率 (Upgrade Success Rate)
- アップグレードが成功裏に完了した割合.
- 指標例: 成功したアップグレード数 ÷ アップグレード試行数 × 100%
#### アップグレード時間 (Upgrade Time)
- アップグレードにかかる平均時間.
- 指標例: アップグレード開始から完了までの平均時間（分, 秒）
#### ダウンタイムなしアップグレード率 (Zero-Downtime Upgrade Rate)
- システムの稼働を中断せずにアップグレードを行えた割合.
- 指標例: ダウンタイムなしで成功したアップグレード数 ÷ 全アップグレード数 × 100%

---
### 理解容易性(Understandability)
---
#### コードコメント率 (Code Comment Rate)
- コードに対するコメントの割合.コメントが多いほど, 理解しやすいコードである可能性が高まります.
- 指標例: コメント行数 ÷ コード全体の行数 × 100%
#### 複雑度 (Code Complexity)
- コードの複雑さを表す指標.複雑なコードは理解が難しくなります.Cyclomatic Complexity（循環的複雑度）などが使用されます.
- 指標例: 関数やメソッドごとの循環的複雑度スコア
#### コードの一貫性 (Code Consistency)
- コードスタイルや命名規則がどれだけ一貫しているかを測定.
- 指標例: コーディング標準に準拠している箇所の割合
#### ナビゲーション時間 (Navigation Time)
- 開発者が特定の機能やコード部分を理解するために要する時間.
- 指標例: ドキュメントを参照してからコードを理解するまでの時間（分, 秒）

---
### 変更容易性(Changeability)
---
#### 変更箇所の影響範囲 (Change Impact Scope)
- システム内で一箇所を変更した際, 影響を受けるコンポーネントやモジュールの数.
- 指標例: 変更による影響を受けたモジュール数 ÷ 総モジュール数 × 100%
#### 変更所要時間 (Change Effort Time)
- 変更を加えるために必要な時間.
- 指標例: 変更依頼からコードの修正・デプロイまでの平均時間（時間, 日）
#### リファクタリング率 (Refactoring Rate)
- コードのリファクタリングが行われた割合.
- 指標例: リファクタリングされたモジュール数 ÷ 全モジュール数 × 100%
#### バグ回帰率 (Bug Recurrence Rate)
- 修正が加えられた際に, 変更によって新たに発生したバグの割合.低いほど良い指標.
- 指標例: 修正後に再発生したバグ数 ÷ 修正したバグ数 × 100%

---
### テスト容易性(Testability)
---
#### テストカバレッジ (Test Coverage)
- 単体テストや統合テストがカバーしているコードの割合.
- 指標例: テストされたコード行数 ÷ 全コード行数 × 100%
#### 自動テスト率 (Automated Test Rate)
- 自動化されたテストケースの割合.自動化が進んでいるほどテスト容易性が高まります.
- 指標例: 自動化されたテストケース数 ÷ 総テストケース数 × 100%
#### テスト実行時間 (Test Execution Time)
- 全テストの実行にかかる平均時間.
- 指標例: テスト実行の合計時間 ÷ テストの実行回数
#### バグ検出率 (Bug Detection Rate)
- テスト中に発見されたバグの割合.
- 指標例: 発見されたバグ数 ÷ 実行したテストケース数 × 100%

---
### デプロイ容易性(Deployability)
---
#### デプロイ時間 (Deployment Time)
- システムのデプロイにかかる時間.デプロイが簡単であれば, 所要時間は短くなります.
- 指標例: デプロイ開始から完了までの平均時間（分, 時間）
#### デプロイ成功率 (Deployment Success Rate)
- 初回デプロイで問題なく完了した割合.
- 指標例: 成功したデプロイ数 ÷ 全デプロイ数 × 100%
#### ロールバック回数 (Number of Rollbacks)
- デプロイ失敗や問題が発生した際のロールバックの回数.
- 指標例: ロールバックしたデプロイ回数 ÷ 全デプロイ回数 × 100%
#### ゼロダウンタイムデプロイ率 (Zero-Downtime Deployment Rate)
- システムのダウンタイムなしでデプロイできた割合.
- 指標例: ゼロダウンタイムでの成功デプロイ数 ÷ 全デプロイ数 × 100%

---
### 監査可能性(Auditability) 
---
#### ログ記録率 (Log Recording Rate)
- システムイベントやユーザー操作が記録されている割合.
- 指標例: 記録されたイベント数 ÷ 発生した全イベント数 × 100%
#### 監査ログのカバレッジ (Audit Log Coverage)
- 監査のために記録される操作やトランザクションの範囲を評価する指標.
- 指標例: 監査可能な操作数 ÷ 全操作数 × 100%
#### ログ保持期間 (Log Retention Period)
- ログデータが保持される期間.監査に必要な期間, データが利用可能であることが重要です.
- 指標例: 平均ログ保持期間（例: 30日, 60日）
#### 監査成功率 (Audit Success Rate)
- 監査で要求されたデータが完全に揃っている回数や割合.
- 指標例: 監査成功回数 ÷ 総監査回数 × 100%
#### 操作追跡精度 (Traceability Accuracy)
- システム内でのユーザー操作やシステムイベントが正確に追跡される度合い.
- 指標例: 追跡された操作数 ÷ 全操作数 × 100%

---
### 観察可能性(Observability) 
---
#### メトリックス収集率 (Metrics Collection Rate)
- システムのパフォーマンスメトリックスが収集される頻度と範囲.
- 指標例: 収集されたメトリックス数 ÷ 設定された全メトリックス数 × 100%
#### ログ収集遅延 (Log Collection Latency)
- ログが生成されてから収集されるまでの遅延時間.遅延が短いほど, 問題の早期検出が可能です.
- 指標例: ログ生成から収集までの平均遅延時間（秒, 分）
#### アラート反応時間 (Alert Response Time)
- システムで発生した問題や異常に対してアラートが発行されるまでの時間.
- 指標例: 問題発生からアラート発行までの平均時間（秒, 分）
#### システム可視化率 (System Visualization Rate)
- システムの状態や動作がどれだけ可視化されているかを示す指標.
- 指標例: 可視化されたシステムコンポーネント数 ÷ 全コンポーネント数 × 100%
#### エラー検出率 (Error Detection Rate)
- ログやメトリックスを通じてシステムエラーがどれだけ検出されているか.
- 指標例: 検出されたエラー数 ÷ 発生したエラー数 × 100%
#### 履歴再現率 (Historical Reconstruction Rate)
- システムが過去の特定の状態をどれだけ正確に再現できるかを示す指標.
- 指標例: 再現できた招待 ÷ 要求された状態 × 100%

---
### 管理容易性(Manageability) 
---
#### 管理タスクの自動化率 (Automation Rate of Management Tasks)
- 日常の管理タスク（設定変更, 更新, 障害対応など）がどれだけ自動化されているかを示す指標.
- 指標例: 自動化された管理タスク数 ÷ 全管理タスク数 × 100%
#### 設定変更時間 (Configuration Change Time)
- システム設定やパラメータの変更に要する平均時間.
- 指標例: 設定変更に要した平均時間（分, 時間）
#### システム更新成功率 (Update Success Rate)
- システムやソフトウェアの更新が成功した割合.
- 指標例: 成功した更新数 ÷ 全更新数 × 100%
#### 平均障害対応時間 (Mean Time to Resolve, MTTR)
- システム障害や問題が発生してから解決されるまでの平均時間.
- 指標例: 障害発生から解決までの平均時間（分, 時間）
#### 管理コスト (Management Cost)
- システムの管理や運用にかかるコスト（リソース, 時間, 人員など）.
- 指標例: 1ヶ月あたりの管理コスト（例: USD/月）

---
### 再利用性(Reusability)
---
#### 再利用可能なコンポーネント数 (Number of Reusable Components)
- システム内で再利用可能なモジュールやライブラリの数.
- 指標例: 再利用可能なコンポーネント数 ÷ 全コンポーネント数 × 100%
#### 再利用頻度 (Reusability Frequency)
- 再利用されたコンポーネントやコードが他のプロジェクトで使用された頻度.
- 指標例: コンポーネントが再利用された回数 ÷ 総使用回数
#### モジュールの汎用性 (Module Generalization Rate)
- 汎用的に使用できるモジュールの割合.特定用途に限定されていない汎用モジュールの割合を測定.
- 指標例: 汎用モジュール数 ÷ 全モジュール数 × 100%
#### ドキュメントの整備状況 (Documentation Completeness)
- 再利用のために整備されたドキュメントの割合.再利用するためには詳細なドキュメントが重要.
- 指標例: 完了したドキュメント数 ÷ 全ドキュメント数 × 100%

---
### 可読性(Readability)
---
#### コメント行比率 (Comment-to-Code Ratio)
- コードに対するコメント行の割合.コメントの充実度はコードの可読性を向上させます.
- 指標例: コメント行数 ÷ コード全体の行数 × 100%
#### 識別子の一貫性 (Naming Consistency)
- 変数や関数の命名が一貫しているかを示す指標.
- 指標例: 命名規則に従った識別子数 ÷ 全識別子数 × 100%
#### コードの平均行長 (Average Line Length)
- コードの各行の平均文字数.行が短すぎたり長すぎると, 可読性が低下する可能性があります.
- 指標例: 総コード行の文字数 ÷ 総行数
#### 複雑度スコア (Cyclomatic Complexity)
- 複雑なコードは可読性を損なうため, 複雑度を示す循環的複雑度などのメトリックスが使用されます.
- 指標例: 関数やメソッドごとの平均複雑度スコア

---
### 独立性(Independence)
---
#### モジュール依存率 (Module Dependency Rate)
- 1つのモジュールが他のモジュールにどれだけ依存しているかを測定.依存性が低いほど独立性が高い.
- 指標例: 依存しているモジュール数 ÷ 総モジュール数 × 100%
#### 外部ライブラリ依存度 (External Library Dependency)
- 外部ライブラリやパッケージに依存している割合.依存が少ないほど独立性が高いとされます.
- 指標例: 外部ライブラリの呼び出し数 ÷ 総呼び出し数 × 100%
#### 関数の独立性 (Function Independence Rate)
- 関数が他の関数やモジュールにどれだけ依存せずに動作するか.
- 指標例: 独立している関数数 ÷ 総関数数 × 100%
#### テストの独立性 (Test Independence Rate)
- 単体テストが他のテストケースに依存せず, 独立して実行できる割合.
- 指標例: 独立して実行可能なテストケース数 ÷ 全テストケース数 × 100%

---
### 攻撃耐性(Attack Resistance)
---
#### 検出された脆弱性数 (Number of Detected Vulnerabilities)
- 脆弱性スキャンやペネトレーションテストによって発見された脆弱性の数.脆弱性が少ないほど攻撃耐性が高いと評価される.
- 指標例: 発見された脆弱性数 ÷ 総スキャン数
#### DDoS攻撃耐性時間 (DDoS Resistance Time)
- DDoS攻撃を受けてから, システムがダウンするまでの時間.長いほど耐性が強い.
- 指標例: システムがダウンするまでの時間（分, 時間）
#### SQLインジェクションブロック率 (SQL Injection Block Rate)
- SQLインジェクション攻撃が防御システム（WAFやIPS）によってブロックされた割合.
- 指標例: ブロックされた攻撃数 ÷ 発生した攻撃数 × 100%
#### 攻撃検知率 (Attack Detection Rate)
- システムが外部攻撃を正確に検知した割合.
- 指標例: 検知された攻撃数 ÷ 発生した攻撃数 × 100%

---
### 侵入検知と防止(Intrusion Detection and Prevention)
---
#### 侵入検知システムの応答時間 (IDS Response Time)
- IDSやIPSが侵入を検知してからシステムが対処するまでの時間.
- 指標例: 平均応答時間（秒, 分）
#### 侵入検知率 (Intrusion Detection Rate)
- 不正アクセスや侵入の検知率を示す指標.検知率が高いほど, 防御システムが有効に機能している.
- 指標例: 検知された侵入数 ÷ 発生した侵入試行数 × 100%
#### 誤検知率 (False Positive Rate)
- 誤って正常な動作を攻撃や侵入として検知してしまう割合.誤検知率が低いほど効果的なシステムといえる.
- 指標例: 誤検知されたイベント数 ÷ 全検知イベント数 × 100%
#### 侵入阻止率 (Intrusion Prevention Rate)
- 検知した侵入に対して, システムが阻止できた割合.
- 指標例: 阻止した侵入数 ÷ 検知した侵入数 × 100%

---
### プライバシー(Privacy)
---
#### データ暗号化率 (Data Encryption Rate)
- システム内で処理・保管されるデータのうち, 暗号化されている割合.
- 指標例: 暗号化されたデータ量 ÷ 全データ量 × 100%
#### アクセス権限違反の検出率 (Unauthorized Access Detection Rate)
- アクセス権限を超えるユーザーによるデータへのアクセスが検知された割合.
- 指標例: 検知された権限違反数 ÷ 総アクセス数 × 100%
#### 匿名化されたデータ比率 (Data Anonymization Rate)
- 処理または送信されるデータのうち, 個人を特定できないように匿名化されているデータの割合.
- 指標例: 匿名化されたデータ量 ÷ 全データ量 × 100%
#### プライバシー侵害イベントの数 (Number of Privacy Breach Events)
システムがプライバシー侵害に相当するインシデントに対処した回数.
指標例: プライバシー侵害インシデント数（一定期間内）

---
### 一貫性(Consistency)
---
#### データ不一致率 (Data Inconsistency Rate)
- システムやデータベース間で, 一貫性が欠けるデータの割合を示す.
- 指標例: 不一致データのレコード数 ÷ 総データレコード数 × 100%
- 意味: この指標により, システム内でどれだけのデータが同期していないかを確認できます.
#### 同期遅延時間 (Synchronization Latency)
- 複数のシステムやデータベース間で, データが同期されるまでの時間を測定.
- 指標例: データ更新から他のシステムに反映されるまでの平均遅延時間（秒, 分）
- 意味: 一貫性が保たれるまでの時間を評価し, システムがリアルタイムで正確にデータを共有しているかを測定します.
#### トランザクション成功率 (Transaction Success Rate)
- データベーストランザクションが一貫した状態で成功する割合.トランザクションの途中で一貫性を失わず, 正確に処理されるかを評価します.
- 指標例: 成功したトランザクション数 ÷ 試行された全トランザクション数 × 100%
- 意味: トランザクションが成功し, 一貫性を保っている割合を示します.
#### 一貫性チェック回数 (Consistency Check Frequency)
- システムがデータの一貫性をチェックする頻度.特定の周期で一貫性を確認することで, データの整合性が保たれているか確認できます.
- 指標例: 一貫性チェックの実行回数 ÷ 総運用時間
- 意味: システムがどれだけ頻繁に一貫性を確認しているかを評価します.
#### 整合性違反検出率 (Integrity Violation Detection Rate):
- システム内で一貫性の欠如やデータの整合性に違反が発生した回数を記録.
- 指標例: 発見された整合性違反の数 ÷ 実行されたトランザクション数 × 100%
- 意味: データの整合性違反が発生した割合を示し, システムの信頼性を評価します.
#### キャッシュ整合性違反率 (Cache Inconsistency Rate)
- データベースとキャッシュ間でデータの一貫性が損なわれる割合.
- 指標例: キャッシュ内の不整合データ数 ÷ 全キャッシュデータ数 × 100%
- 意味: キャッシュシステムでの整合性の問題を評価する指標.
#### クエリ整合性成功率 (Query Consistency Success Rate)
- クエリの結果が正確かつ一貫している割合.
- 指標例: クエリの整合性チェックで成功した回数 ÷ 総クエリ数 × 100%
- 意味: クエリの結果が正確に取得されているか, 一貫性が保たれているかを測定します.
.

---
### 互換性(Compatibility)
---
#### 対応OS/デバイス数 (Number of Supported OS/Devices)
- システムやソフトウェアが正常に動作するOSやデバイスの数.
- 指標例: サポートしているOS/デバイス数 ÷ ターゲットOS/デバイス数 × 100%
#### ブラウザ互換性スコア (Browser Compatibility Score)
- システムが異なるブラウザで正しく動作するかを評価する指標.
- 指標例: 各ブラウザの互換性テスト結果の平均スコア（例：1〜10スケール）
#### 依存性の数 (Number of External Dependencies)
-  システムが外部ライブラリや特定の環境に依存する数.依存性が少ないほど互換性が高いとされる.
- 指標例: 使用している外部ライブラリ数 ÷ 総モジュール数

---
### 移植性(Portability)
---
#### コード変更量 (Code Modification Rate)
- システムが異なるプラットフォームで動作するために必要なコード変更の量.
- 指標例: 移植時に変更されたコード行数 ÷ 全コード行数 × 100%
#### 移植に要する時間 (Porting Time)
- システムを新しいプラットフォームに移植するのにかかる時間.
- 指標例: 移植開始から完了までの時間（時間, 日）
#### 移植可能なプラットフォーム数 (Number of Portable Platforms)
- システムが適応できる異なるプラットフォームの数.
- 指標例: 移植可能なプラットフォーム数 ÷ 対応プラットフォーム数 × 100%
#### 移植成功率 (Porting Success Rate)
- 異なるプラットフォームにシステムを移行する際の成功率.
- 指標例: 成功した移植数 ÷ 試行された移植数 × 100%

---
### 相互運用性(Interoperability)
---
#### API互換性スコア (API Compatibility Score)
- システムが異なるシステムやOS間で, APIを介して正しく連携できるかを評価する指標.
- 指標例: API互換性テスト結果の平均スコア（1〜10スケール）
#### データフォーマット互換率 (Data Format Compatibility Rate)
- 異なるシステム間で, データフォーマットの互換性がどれだけ確保されているか.
- 指標例: 正常に共有されたデータ数 ÷ 全データ数 × 100%
#### プロトコルサポート数 (Number of Supported Protocols)
- 異なるシステムと通信する際にサポートされているプロトコルの数.
- 指標例: サポートプロトコル数 ÷ 必要プロトコル数 × 100%
#### データ変換成功率 (Data Transformation Success Rate)
- システム間でデータフォーマットの変換が正常に行われた割合.
- 指標例: 成功したデータ変換数 ÷ 総変換数 × 100%

---
### 設定可能性(Configurability)
---
#### 設定オプション数 (Number of Configuration Options)
- ユーザーがシステム内でカスタマイズできる設定オプションの数.
- 指標例: カスタマイズ可能な設定項目数 ÷ 総設定項目数 × 100%
#### 設定変更時間 (Configuration Change Time)
- ユーザーが設定を変更するのにかかる平均時間.
- 指標例: 設定変更にかかる平均時間（分, 秒）
#### カスタマイズ成功率 (Customization Success Rate)
- ユーザーが意図した通りにシステムをカスタマイズできた割合.
- 指標例: 成功したカスタマイズ回数 ÷ 試行されたカスタマイズ回数 × 100%
#### 設定保存成功率 (Configuration Save Success Rate)
- 設定が正しく保存された割合.
- 指標例: 設定の保存成功数 ÷ 保存試行回数 × 100%